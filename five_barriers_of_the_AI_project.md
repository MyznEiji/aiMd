# AIのプロジェクトを始めるとぶち当たる5つのハードル



現在AIに対して多くの人がもつイメージとして、**Over Estimate(過剰な期待)**と**Under Estimate(過小な期待)**という問題があります。Over Estimate(過剰な期待)はAIを使うと全ての問題が自動的に解決されるというもので、Under Estimate(過小な期待)はAIを使えば実は簡単に解決される問題なのにそのことに気づいてもいないということです。

今日では、比較的簡単にAIを使うことのできるツールがたくさんあるので、こうした機会を利用して、自分たちのデータをもとにどんどん使ってみて、AIを使うと実際に何ができて、何ができないのか、さらにどういったことが問題になるのかなどを理解していくことで、自分なりの正しい期待値を設定していくことが重要だと思います。

- [What AI can and can't do (yet) for your business](https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/what-ai-can-and-cant-do-yet-for-your-business)



# AIプロジェクトにおける５つのハードル



## 1. データのラベル付け



AIのシステムは一般的には正解付きのデータによってトレーニングされる必要があります。（日本語ではこれを教師付き学習と呼ぶ）このトレーニングのためには大量のデータを必要とし、さらにこのデータに正解となる答えをラベル付けする作業はものすごい手間と時間がかかります。

例えば、自動運転のテクノロジーを開発している会社は、試験走行から得られる膨大な時間のデータに何百人という人が手作業で注釈を入れて（ラベル付け）から、そのデータを使ってシステムをトレーニングしています。

この手作業の部分を自動化または効率化させる試みとして、教師なし学習や半教師付き学習などを組み合わせたり、強化学習のように報酬と罰を決めることによって、後はアルゴリズムがシミュレートしながらある意味データを勝手に作っていったりというものがあります。さらにはここ最近のトレンドとしては

__GAN(Generative Adversarial Networks / 敵対的生成ネットワーク)__

> 二つの反するディープニューラルネットワークのモデル（一つは相手を騙すためのデータを作るためのモデル、もう一つはそれが正しいか間違っているかを判断するためのモデル）

という手法を使ってトレーニングすることで少ないデータから多くのデータを仮想的に作り出すやり方などが研究されています。





## 2. ブラックボックスな予測モデル



予測、レコメンデーション、意志決定の精度を上げるのに使われたりする機械学習のモデルはディープラーニングのモデルを筆頭にその中で何が起きているのかが人間には理解しにくいという問題があります。人間が実際に意志決定を行うためには、なぜそういう予測の結果が出たのかの理解が必要になります。

例えば、お金を貸すための審査をAIにやらせる場合、なぜある人は安く借りれて他の人は高いのかという説明は、もちろん法律で求められているということもありますが、貸す側で意志決定をおこなっている人間にとって、どういう基準で金利が決まっているのかよく分からないというのはありえません。

そしてこれこそがAIが本来ならもっと浸透しても良いエリアに浸透していない一つの理由です。つまり、多くの分野ではコンピュータによって行われる処理に対して、どのようにしてその結果にたどり着いたのかという説明を求められるからです。

こうしたブラックボックスなモデルがどのようにして予測結果を導いているのかを解き明かすための手法として、最近は__LIME(Local Interpretable Model Agnostic Explanations)__という手法が注目されています。

> 一部のデータをモデルに渡し、その中の属性がどのようにして予測結果に影響を与えているのかを明らかにするというもので、ディープラーニングだけでなく、機械学習のなかでも予測精度を上げるためによく使われるアンセンブル・ラーニング（集団学習）モデルにも使えるなど、様々なモデルで使うことができます。





## 3. トレーニングのために必要になる大量のデータ



AIのモデルの予測精度を上げるためには一般的には大量のデータを必要とします。例えばディープラーニングのモデルでそれなりの結果を出すには少なくとも何百万といったレベルのデータが必要になります。（西田：これはスタートアップのように持ってるデータ量がまだ少ない場合や、必要なデータをまだ集め始めてばっかりの時にチャレンジとなります。）

最近は__ワン・ショット・ラーニング__という、AIが少ないデータから予測対象を学習することを可能にするという手法が注目されています。





## 4. AIモデルの一般化



現在はAIモデルと言っても、結局は狭い分野で一つのことをこなすといった用途に限られ、一般に期待されているような人間のような知能をもって様々なタスクを行っていくには至っていません。つまり、一つのプロジェクトで作ったAIのモデルは使い回しができないので、企業はプロジェクトごとに、さらには用途ごとにAIのモデルを一から作り直す必要があるわけです。

最近では一つの用途で作られたモデルが別の似たような用途でも使えるようにするという__トランスファー・ラーニング__という手法が研究されています。アルファ碁で有名なDeepMindの研究者はシミュレーションの中で学習したモデルをロボットの腕を動かすために使うということをやっています。他にも、石油やガスの生産者であれば油井のメンテナンス時期を予測するために作ったモデルを使ってパイプライン、採掘プラットフォームのメンテナンス時期も予測することができるでしょう。

さらに、機械学習のモデルのデザインそのものを自動化するという__メタ学習（meta-learning)__という手法にも注目が集まっています。Google Brainでは自動機械学習(AutoML)を使ってイメージの識別のためのニューラル・ネットワークのデザインを自動化しています。これらの手法は最近では人間によってデザインされたものと同等の結果を出すまでになっています。





## 5. データとアルゴリズムの中のバイアス



AIのモデルがデータをもとに作られるということは、どういったデータを使うのか、データをどこからとってくるか、どのようにしてとってくるかといったところに人間の__バイアス__が入ってしまう余地があります。アメリカの場合であれば、白人の多い地域で取得されたデータで作ったモデルには白人以外の予測にはまったく役立たないかもしれません。

そして、このバイアスというのが実は一番やっかいで、一度モデルの中に入ってしまうとなかなかそれがバイアスだと気づくことができません。高度なデータサイエンス、独自のデータとアルゴリズム、客観的な分析などといった旗印のもとに、しばらく長い間隠されてしまっているというケースが多々あります。





## 最後に



もしあなたがAIのテクノロジーの進化に対して無視を決め込み、先に始めた人たちの成功事例を参考にあとで急速に挽回できると思っているのなら、もう一度考え直したほうがいいでしょう。現在のようにテクノロジーが毎日ものすごいスピードで進化している世界では、立ち止まっている場所から一気に飛躍するなどというのは夢の様な話です。なんといっても、ちょっと前までできないと思っていたことが、すでに今日にはできるようになり、それをもとにさらに新たな手法が生まれていくという世界なわけですから。

------

以上、５つのハードルとなる部分を抜き出して、簡単に要約してみました。以下は私の私見ですので、興味のある方は読んでいただければと思います。





