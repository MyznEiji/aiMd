# AirbnbのデータサイエンティストはなぜRが好きなのか?



[![image.png](https://camo.qiitausercontent.com/e844eb82d88cb38da93806bc63987097dc2ee47d/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343937382f31303230633933322d306337312d363337382d626537612d3238396530326639656539302e706e67)](https://camo.qiitausercontent.com/e844eb82d88cb38da93806bc63987097dc2ee47d/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3132343937382f31303230633933322d306337312d363337382d626537612d3238396530326639656539302e706e67)



今シリコンバレーで、もしくは世界中のスタートアップ業界で一番ホットな会社といえば[Airbnb](https://www.airbnb.com/)と言っても過言でないのでしょうか。日本では民泊のプラットフォームとして知られていますが、今や3兆円近い企業価値がついている超ユニコーン企業です。

私も日本に行く時はホテルでなく、いつもAirbnbで普通のアパートを一週間ほど渋谷のあたりに借りますが、使いやすく、コストパフォーマンスもよく、出張をするときには欠かせないサービスです。



Airbnbnはシリコンバレーのスタートアップの中でも特にデータの使い方がうまい会社として有名で、いろいろとデータに関するツールをオープンソースとして公開もしています。

そんなAirbnbのデータサイエンティストたちの間ではRというプログラミング言語が一番人気があるというのは以前から広く知られていることですが、今回、彼らがどう社内でRを使っているのか、

どのようにプロダクトに関するインサイトを抽出し、A/Bテストなどの実験結果を評価し、予測モデルを作り、さらにどう社員のためのトレーニング、教育を行っているかなどに関してかなり詳しい情報を[こちら](https://peerj.com/preprints/3182.pdf)の方に公開していたので、以下に著者の許可を得た上でさらっと訳してみました。

以下筆者による日本語訳

------



# How R Helps Airbnb Make the Most of Its Data: Great overview of how R is used at Airbnb

[Original Post URL](https://peerj.com/preprints/3182.pdf)

*By Ricardo Bion (Ricardo.Bion@airbnb.com), Robert Chang (Robert.Chang@airbnb.com), Jason Goodman (Jason.Goodman@airbnb.com)*





# Introduction

Airbnbのデータサイエンス・チームはデータを理解するために毎日Rを使っています。Pythonを使ってデータサイエンスしている人達も多いですが、AirBnBではRが一番良く使われているデータサイエンスのプログラミング言語です。

最近の社内のデータサイエンス・チームに対してのアンケートでは、73％のデータサイエンティストとアナリストがRを使うことに関して自分たちをエキスパート（専門家）・レベルだと思っています。そして、58％の人たちがRを毎日のようにデータ分析に使います。

Rはデータ分析の一連のフローの中で全ての場面で使われます。例えば、探索的(Exploratory)データ分析、予測モデルの作成、ビジネス・パートナーと結果を共有するといった場面です。

この記事の中ではRがどのように使われているか、さらに、これからRを使ってデータをもっと理解していきたいと考えている人たちへの実用的なアドバイスを共有したいと思います。





# Data Science at Airbnb

Airbnbは191カ国、65,000以上の町で泊まることのできる何百万もの泊まる場所を提供するコミュニティータイプのマーケットプレイスです。

宿以外にもExcperienceというサービスは地域のコミュニティーや面白いことを体験することを可能にしますし、Placesというサービスはそれぞれの町に住むローカルのお気に入りを発見することを可能にします。



この会社の成功の大きな部分はデータサイエンスチームによるところが大きいです。

データサイエンス・チームの最初のメンバーはこの会社の最初に雇われた社員10人のうちの一人です。

現在はこのチームはデータサイエンティスト、データエンジニア、ビジネス・アナリスト、機械学習エンジニア、そしてプロダクトやIT基盤にフォーカスしたデータチームで、Airbnbのプラットフォームのほとんど全ての部分に関わっています。



それでは、データサイエンスとはそもそも何でしょうか？それは、要は、私達にとってはよりよい意思決定を支えるためにデータを使うということです。

Airbnbのデータサイエンティスト達は会社がよりデータをもとに意思決定を行えるための多くのタスクに責任をもっています。

私達は、ユーザーの行動履歴などのログデータを取る、データの加工のパイプラインを作る、指標を定義する、教育のためのコンテンツや環境を作る、社内で使うデータ関連のツールを作る、レポートやダッシュボードを作る、といった作業をしています。

しかし、そうした私達の仕事を、大きく３つのフォーカスしたカテゴリーに分けることができます。それは、プロダクト・インサイト、実験、予測モデルとなります。







# Product Insight (プロダクト・インサイト)



プロダクト・インサイトは、特に終わりが決まっているわけではなく、基本的には探索的（Exploratory)な分析の仕事になります。プロダクトとは主に、ホーム、宿泊先、場所、体験を含むAirbnbのウェブサイトとモバイル・アップになります。始める前に特に何か特定の見つけ出したいものが決まっているわけではなく、逆にゴールはプロダクトをより良くするための機会を見つけ出すことです。

例えば、どういったタイプのゲストがある地域に泊まっているのか、なぜ新しホストはブッキングできてないのか、どの町で宿の供給が足りてないのか、といった質問をしてそれに答えていくことが、プロダクト・インサイトに関する仕事です。そしてこうした分析から得られたインサイトが新しいプロダクトのアイデアになったり、ユーザーの行動に関する仮定となったりします。そして、こうした仮定を検証するのが次の実験の仕事になります。







# Experimentation (実験)

実験、つまり一般にはA/Bテストとして知られているもののことですが、これがデータドリブンなプロダクト開発の重要な部分を占めます。

実験の目的はチームがユーザーエクスペリエンスの改善に役立つと思っている仮定をデータを使って統計的に検証することです。

もしそういった仮定が正しいと実証されたら、それに基づく変更がウェブサイトやモバイル・アップを通してすべてのユーザーに届けられることになります。ほとんど全ての仮定やアイデアはこうしてコントロールされた実験を通して検証されます。

そして、新機能がどうブッキング、カスタマーサポート・チケット、ユーザーのレビューのスコア、宿を貸すホストの離脱率といった何十ものKPIにどう影響するのかをチェックします。



さらに、こうした実験というのは実はそうした機能をデザイン、テスト、そして実装したチームにその成果に貢献したということを周りの目からもはっきりと認識されるようにするためであり、そうした変更がブッキングなどのような重要な指標が悪くならないようにするというためでもあります。



データサイエンティストはこうした実験の全ての段階に関わっています。実験を始める前にはパワー分析を行って、どれくらいの間実験をしなくてはいけないのかということを決めます。そして、どのように実験が実行されるべきか、最終的に成功しているといえるためにはどの指標を見ている必要があるのかという仕様を最初に決めます。







## Predictive Modeling (予測モデル)



AirBnBでは、よく知られた機械学習を使ったアプリケーションとしてスマート・プライシング(価格)という、ホスト（物件の提供者）が最適な値段をレコメンドする機能を提供しています。

これは、どの日に値段をつけようとしているのか、物件の場所はどこか、どういった施設なのか、過去のブッキングデータなど、様々な属性から最適な値段を導き出します。

機械学習のプロジェクトを最初から最後まで行うのはコストも時間もかかります。

そしてこうした予測モデルを作る時に実験的にいろんなモデルを試す必要があるのですが、こうしたときにRはすごく便利です。なぜなら予測モデルの精度を上げるために、データの加工、属性の生成などを行う必要があるのですが、Rだとそれがものすごく簡単にできるからです。



例えば、宿のリストとゲストのレベルに合わせて売上を予測するために、データサイエンティストはたくさんの予測モデルをプロトタイプとして作り、その中から最も使えるものをRMSE(二乗平均平方根)という指標を使って選びことで、そのプロトタイプが最も可能性がありそうだと判断していきます。







# R at Airbnb



ツールとしてはRだけが存在するわけではありません。むしろ普通は、データを収集して、処理して、そして分析するという一連の長いプロセスの最後の方の段階で使われます。



- 最初はログデータです。Airbnbでユーザーが行った行動、例えば検索したり、ホストに連絡したり、カスタマー・サポートに連絡したりといったイベントです。

- もう一つは物件の情報や、取引に関する詳細です。こちらはMySQLデータベースに保存されてます。

  こうしたデータは最終的にAWS上のデータウェアハウスに流し込み、S3と言うサービスを使ってHDFSに安全に保存されます。

- そして、毎晩たくさんのETL(Extract, Transform, and Load) のタスク・ジョブが私達のオープンソースのワークフロー管理のツールであるAirflowを使って実行され、必要な指標の計算、生データからの集計などがその後で行われる詳細な分析、予測モデルの作成のために行われます。

- 様々なデータ分析ツールがユーザーのスキルレベルによって用意されています。データの可視化にはTableau、そして私達のオープンソースのデータ可視化ツールであるSupersetといったツールがよく使われます。

- SQLに自信のある人たちはSQL Labを使ってデータウェアハウスに直接クエーリをかけてデータを取ってきます。データサイエンティストは様々なツールを使いますが、そのなかでも一番重要なのはRです。



Rはすでに述べた３つのフォーカス領域のどれでも必須となるツールです。プロダクト・インサイトではdplyr等のパッケージを使ってデータを様々な角度からものすごい速さで集計して分析していきます。ggplot2のようなデータの可視化のパッケージと組み合わせることによって、Rはデータサイエンティストがデータの中を飛び抜けるかのように分析していくことを可能にします。



実験のフェーズでは、pwrというパッケージを使って統計のテストを行い、高いスタンダードを維持します。機械学習では、これから開発していく機能が投資に値するだけの正解を生み出すことができるのかを予測するためのプロトタイプとしての予測モデルを作ります。以下は一部の例です。





## Product Insights

Rは私達がプロダクト・インサイトに関する仕事をAirbnbで行うのに3つのエリアで可能にします。社内のパッケージに、tidyr、dplyrを組み合わせた探索的データ分析、社内のカスタムスタイルとggplot2などのパッケージを使ったデータの可視化、それから社内のKnowledge Repositoryとrmakrdownを使った再現可能なリサーチです。





### Exploratory Data Analysis

データ分析はまずデータの抽出から始まります。AirbnbではHiveやPresto経由でSQLを使ってHDFSからデータを取ってきます。私たちは、この作業に関する詳細を抽象化し、ユーザーが単純にSQLを使ってデータを簡単にRのデータフレームにインポートすることができるようにしました。データがメモリーに入ったら、magrittrのパイプを使ってデータの加工と分析に関わるオペレーションを一つのパイプラインとして実行していきます。データの抽出、加工、可視化、予測モデルの作成と言ったオペレーションはほんの数行でできますので、すばやく分析、可視化を繰り返しながら分析していくことができます。ここではdplyr、tidyr、broom、purrrなどのパッケージを使います。





### Data Visualization

私たちはggplot2というRのパッケージを使ってアドホックで探索的な可視化を行い、公開に耐えるほどにカスタマイズされたグラフを作ります。前述したデータをきれいにして加工するためのパッケージと組み合わせることによって、分析者は素早くインサイトを質の高いグラフに変換することができます。静的なグラフをggplot2を使って作る以外にも、plotly、leaflet、dygraphs、DiagrammeR、shiny等のパッケージを使ってインタラクティブなグラフやダッシュボードを作ります。





### Reproducible Research

Airbnbでは、全てのRを使った分析はコード、グラフとともにrmarkdownの形で一つのドキュメントして残されます。そうしたドキュメントは、ビジネスパートナーと共有される前に、手法やコードの書き方の点などからそれぞれの分析のエリアの専門家、または使われた技術の専門家によって注意深くレビューされます。

一度レポートの準備ができると、Rのコードはマージされ、レポートはKnowledge Repositoryと呼ばれる社内ウェブサイトにて共有されます。Knowledge RepositoryとはGithubをベースにしたPythonとFlaskで作られた社内ウェブアプリケーションで、検索、サブスクリプション、タグなどと言った機能がついてます。こうして共有された幾つかのレポートは最終的にアカデミック・ジャーナルや外部のブログに投稿されたりもします。こちらにそうした例があります。“[How Airbnb uses Machine Learning to Detect Host Preferences](https://medium.com/airbnb-engineering/how-airbnb-uses-machine-learning-to-detect-host-preferences-18ce07150fa3)” (Ifrach 2015) and “[How well does NPS predict rebooking?](https://medium.com/airbnb-engineering/how-well-does-nps-predict-rebooking-9c84641a79a7)” (Qian 2015)

> Knowledge Repositoryはソフトウェア開発とアカデミック・リサーチからのベストプラクティスを活かしています。

こうして私達の分析をrmarkdownのフォーマットとしてKnowledge Repositoryに残すことにはたくさんの利点があります。まず、社内のテクニカルでない人も含めて誰もが、簡単に自分の興味のあることに関連したすでになされた分析を探すことができます。さらに、データサイエンティストが他の人達が行った分析から、新しい分析の手法などを学ぶことがでますし、以前使われたコードを使いまわすこともできます。そして、様々なチームが最新のリサーチにキャッチアップするためのプロセスを簡単にすることできます。こうしたことはrmarkdownという共通したフォーマットなしには成し遂げることができなかったでしょう。





### Experimentation

最初の頃はRを使って実証的な分析をマニュアルでやっていました。私達の行っている実験を統計テストをして評価する前に、実験にアサインされているユーザーのログとブッキングデータ、他の重要な指標を一緒にします。そして、Shinyベースのアプリケーションを作ってこうした分析をたくさんの人ができるようにしてました。しかし時間が経つに連れて、何百もの実験テストを同時に行うようになるとShinyでは私達のニーズをスケールという観点で満たすことができなくなりました。ということで、こういったチャレンジを克服するために、RubyやPythonで作られているデータ・インフラストラクチャにインテグレートしやすく、さらに私達のエンジニアリングチームがサポートしやすいシステムを作る必要がありました。そうして、Experiment Reporting Frameworkと呼ばれるデータパイプラインと実験テストのステータスをモニターし分析するためのウェブサイトを作り上げました。これはRを使うことによって、素早くプロトタイプを作り上げることで、そうしたシステムを使うことになるであろうユーザーの要件を理解し、その価値を外のチームにデモンストレートし、そうしてもっとスケールするシステムをしっかりと作り上げていくことができるといういい例だと思います。

今日では、ほとんどの実験テストは自動化されているとはいえ、Rはもっと複雑な実証的な分析や深い分析が必要なときなどに重要な役割を果たします。そういった分析は、特別に複雑は実験のセットアップや、別に計算する必要のある指標や、T検定よりもっと高度な統計分析といったものを含みます。他にも、Rを使って実験の割当てがちゃんと行われているかチェックしています。さらに、私たちは可能な限り作業を自動化することに余念がありません。もし自分たちが同じようなアドホックの実証的な分析を繰り返し行っていた場合はそれはツールのレイヤーに落とし込むようにしています。

> 例えば、実験にアサインされてからの時間を基に手動で計算していた指標がありましたが、何度か同じようなことを繰り返した後で、Rの関数を作ることで自動化しました。最終的にはこうした機能はメインの実験システムの方に統合されています。





## Predictive Modeling

もちろんRはデータをきれいにしたり加工したりすることに関してものすごく効果的で使いやすいツールでありますが、それ以上に予測のモデルを作ることに関してはとてもパワフルです。それは、Rのコミュニティーが作り上げてきた最適化、機械学習、経済指標のテクニックにその力を見ることができます。Airbnbではたくさんのデータサイエンティスト達がこうしたパッケージを使ってモデルを作っていきます。以下に3つほど私達のチームがどうやって予測モデルを作っているかの例を共有します。





### Airbnb Guest Service Fee Optimization using NLopt package

予約が完了すると、Airbnbはゲストにサービス料を予約料金の5％から15％の間でチャージします。このサービス料は、予約の期間の長さやリストのタイプなど様々な要素によって決まります。私達のデータサイエンティスト達がこの料金をゲストとホストによって公平になるようにしながらどう最適化すればいいかを調べるというプロジェクトを行いました。例えば、予約料金が大きいときにはサービス料のレートは低めに設定したりということです。ちなみに私たちは、需要の多いニューイヤー(新年)やクリスマスの時期に高くするといった、サーチャージと言うことはしません。過去にはいくつかのサービス料の体系を用意して、サービス料がブッキングの需要にどう関係してくるのかということを学びました。この関係性がわかると、われわれのプラットフォームの上での売上を最大限にするためのサービス料のカーブを描くことができます。この実験には、非線形の最適化の問題としてNLoptというRパッケージを使っています。この結果から私たちはどうやってサービス料を設定すればいいかというガイダンスを作ることができました。





### Building A Marginal Returns Model in R

どのようにして、Airbnbに宿をリストしてくれる新しいホストを増やすための投資をすればいいでしょうか。そして、いくらくらい投資すればいいでしょうか。こうした質問に応えるために私達のデータサイエンティストはCobb Douglasのような経済指標のモデルを作り、それぞれのマーケットにおける需要、供給から予約の数を導き出します。

過去の供給（予約することのできる泊の数）と需要（予約しようとしている人たちの数）のデータを使うことによって、両方からログを取り、Rの中で伸縮性の推測値を計算することができます。そして、この予測モデルと、将来の供給と需要のフォーキャストをもとに、ある特定のマーケットに宿を追加することによってどれだけの予約が成立する数としてのリターンがあるかを予測する事ができるわけです。こうして私たちはどのマーケットが一番リターンが大きくなるかを把握でき、それをもとに、どのマーケットから追加の宿の供給を増やしていくか効率的に決めていくことができるのです。





### Causal Tree

新しい機能の実験をする時、どのタイプのユーザーがもっとも影響を受けるかというのはデータサイエンティストがよく受ける質問です。これはよく手作業でデータと格闘しながら探していく作業になるのですが、最近はCausalTreeという機械学習を因果推論に適用する手法を試しています。このアルゴリズムは、コントロールグループとトリートメントグループの差が最も大きくなるように反復的に実験データをパーティションに区切ってくれるというものです。

こうしたアルゴリズムや新しいやり方はまず最初にRで実装されることが多いので、私たちはオープンソース版のこのアルゴリズムを使ってすぐに私達の分析を行うことができました。これは、自分たちでそうしたアルゴリズムを一から作る必要なしに、他の統計学者やアカデミアの人たちの仕事を利用することで、素晴らしい分析を行っていくことができるといういい例です。







# How We Support R Usage





## Community (コミュニティー)

他の企業と一緒で、AirBnBも社員にどうやってデータサイエンスを教育するかという様々な取り組みが行われていますが、最も体系立ててやっているのはRを教えるクラスです。新しく採用されたデータサイエンティストは一週間のデータブートキャンプのクラスに参加します。

現場に配属されるとスキルアップのために他の人達からどんどんと学んでいくことを期待されます。すでに述べたように、ピアレビューを通して他のデータサイエンティストたちから分析、リサーチに対するフィードバックが与えられます。さらにスキルアップしていくのに最も効果的なのは、 Knowledge Repository に共有されている他の人達のコードを見て、どうやって似たような問題を解決していったかを学ぶということでしょう。あとは、SlackにRのためのチャンネルがあるのでそこで自由に質問したりアドバイスを受けたりすることができます。

社内では、勉強会ランチ、勉強グループ、チュートリアルなどの機会を使って、積極的にRに関する新しいパッケージや現在開発しているものに関する情報を共有します。さらに、教育のための予算を確保しているので、データサイエンティストはDataCamp（オンラインでデータサイエンスを学ぶことができるウェブサイト）のような外部のトレーニングコースやUseR!などのカンファレンスなどにどんどん参加することができます。

私たちは最近Rに関連したクラスを社内のデータ・ユニバーシティのために3つほど開発しました。これらのクラスは、Rを使った分析の始め方、データの可視化、社内のRパッケージの使い方と貢献の仕方です。

外部では、Airbnbの外のRコミュニティーと関わっています。最近ではrOpenSciをスポンサーしましたし、ggtech、RPrestoといったオープンソースのパッケージにも貢献していますし、Shiny Developer ConferenceやUseR!といったカンファレンスでも発表しています。さらにHadley Wickham、Ramnath Vaidyanathanといった有名なR開発者をゲスト・スピーカーとして招聘したりもしています。





## Tooling (ツール)

あらゆるチームでRを使いやすくするために、私たちはRbnbというデータ分析のために役立つ関数とテンプレートがつまったパッケージを開発しました。このパッケージは社内のGithubにホストされていてだれでもソースを見たり、貢献したりすることができます。

20名以上の人たちから貢献された90以上の関数があります。データの統計的な推測からグラフのカスタマイゼーションまで様々な機能があります。コンセプトとしては、チームの誰でも何か問題を解決した時にそれが他の人にとっても役立つと思えばそれを一般的な関数としてRbnbに登録し、他の誰もが使えるようにするということです。

最近、データサイエンティストの誰もがRパッケージを作ることができるようにするためのクラスも開始しました。チームの中でRを使う半分以上の人達がすでに参加し、Rbnbパッケージにさっそく貢献し始めています。メーリングリストを使って新しい機能や貢献に関するニュースを発信し、貢献した人たちが評価されるようにも努めています。

最初の数年はRbnbは比較的少ない貢献者しかいませんでした。チームは小さかったため、一般的に使える関数を開発することに対するリターンが少なかったためです。今ではチームはかなり大きくなったため、こうした仕事には大きな意味があります。ただ、一人の人がこうしたパッケージの開発に責任を持つというわけではなく、チームみんなでの努力の成果ということになりますので、さらなる貢献を促すためにどのように正しいインセンティブと報奨を与えるかというのが重要なチャレンジとなります。

最近ではもっとこうした貢献にインセンティブを与えるようないくつかの仕組みを試しています。例えば社員のパフォーマンス評価にこうした貢献が与えるウェイトを大きくしたり、こうしたクラスに参加した人やRbnbに貢献した人たちに与えることのできる、ラップトップに貼るステッカーを作ったりしています。

私達のAirbnbでのツール開発や教育に関するもっと詳しいディスカッションにかんしては”[Using R packages and Education to Scale Data Science at Airbnb](https://medium.com/airbnb-engineering/using-r-packages-and-education-to-scale-data-science-at-airbnb-906faa58e12d)”という別のブログポストを参照して下さい。





# Advice For Practitioners (修行者へのアドバイス)

私たちはチームとして長い道のりを歩んできましたが、その途中でたくさんのことを学びました。ここに、これからRを使ってデータ分析をしていく、または学んでいくという方たちのためにいくつかの推薦できる方法をまとめてみました。

まず最初に、プロダクション・データベースのような基盤となるデータにRでアクセスできるようにする関数をなるべく早い時期に作ることをおすすめします。最初の時期は、Rは新しいデータツールのプロトタイプに適しています。その後十分に大きなチームになったら内部で使うRパッケージを作って、分析者同士がコードを共有できるようにするべきで、貢献を促すような文化を作り、さらにツールを作ることで全チームの生産性が上げていくべきです。内部で作るパッケージに関しては、社内の標準のチャートなどのためのスタイルを作ることが役立ちますし、データチームのブランドを再確認するのにも役立ちます。

ピア・レビューや分析をあとで再現することができるようにするためにも、Github、rmarkdown、そして私達がオープンソースとして公開したKnowledge Repositoryを使うことをおすすめします。チームのメンバーのための継続的な教育やトレーニングに投資することもおすすめします。最後に、データ関連の仕事をするにあたって、Rだけが唯一の言語ではありません。多様性のあるチームを育てることが長期的には大きな成果を生み出すことになります。

Rはデータサイエンティストのツールセットの中で欠かせない重要なものです。私たちは、この言語をサポートできることを誇りに思います。他のどんな企業も、データを使ってできるだけたくさんの成果を上げたいのであれば、Rをデータサイエンスの言語として採用することをおすすめします。